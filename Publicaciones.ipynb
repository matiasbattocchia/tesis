{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/12/17\n",
    "\n",
    "### Sentiment analysis algorithms and applications: A survey\n",
    "\n",
    "* SA sentiment analysis\n",
    "* SC sentiment classification\n",
    "* RB resource building\n",
    "* TL transfer-learning\n",
    "* ED emotion detection\n",
    "* FS feature selection\n",
    "\n",
    "#### Feature selection\n",
    "\n",
    "* Gini index\n",
    "* Information gain\n",
    "\n",
    "5/12/17\n",
    "\n",
    "#### Sentiment classification\n",
    "\n",
    "Datasets desbalanceados. Las opiniones positivas suelen ser más que las negativas.\n",
    "\n",
    "Los árboles de decisión usan criterios de separación que no son los usuales (por ejemplo presencia de un conjunto de palabras).\n",
    "\n",
    "6/12/17\n",
    "\n",
    "7/12/17\n",
    "\n",
    "5.1 Emotion detection.\n",
    "\n",
    "It was argued by Plutchik [102] that there are eight basic\n",
    "and prototypical emotions which are joy, sadness, anger, fear,\n",
    "trust, disgust, surprise, and anticipation.\n",
    "\n",
    "11/12/17\n",
    "\n",
    "### Temporal Patterns of Happiness and Information in a Global Social Network: Hedonometrics and Twitter\n",
    "\n",
    "English words, as they appear in natural\n",
    "language, are biased toward positivity, a phenomenon we explore\n",
    "elsewhere [59].\n",
    "\n",
    "16/12/17\n",
    "\n",
    "Usaron una lista anotada de *evaluación de felicidad* —es decir de $h(w_i)$— de 10 mil palabras (del 1 al 9). Son las palabras más frecuentes de la unión de varios corpus. Una lista similar y preexistente pero breve es **ANEW**.\n",
    "\n",
    "Se hicieron análisis por día a los largo de varios años y por hora a lo largo de varios días. La felicidad es relativa, es decir que a $h_{avg}$ se le sustrajo un $h_{ref}$ absoluto. También se tuvieron en cuenta ventanas de un mes (*felicidad ambiente*) y referencias semanales, ya que habían tendencias diarias y semanales.\n",
    "\n",
    "Usan una medida de contenido de información (diversidad):\n",
    "\n",
    "$N_s = 1 / S = 1/\\sum{p_i^2}$\n",
    "\n",
    "#### Conclusiones\n",
    "\n",
    "Evaluaron la felicidad de todo tipo de palabras. Algunas quizás no tienen una connotación aparente, por ejemplo *vehículo*, y otras quizás sí, como *Israel*. Quizás las entidades tengan más chances de connotación emocional.\n",
    "\n",
    "### The Geography of Happiness: Connecting Twitter Sentiment and Expression, Demographics, and Objective Characteristics of Place\n",
    "\n",
    "La metodología es la misma que la de la publicación anterior. La novedad es el uso de la información geográfica de los twits y las comparaciones con diversos índices de felicidad y de desarrollo humano.\n",
    "\n",
    "### Climate Change Sentiment on Twitter: An Unsolicited Public Opinion Poll\n",
    "\n",
    "La metodología sigue siendo la misma. Esta vez también analizan a la felicidad de subconjuntos de tweets definidos por una palabra clave.\n",
    "\n",
    "### Measuring the Happiness of Large-Scale Written Expression: Songs, Blogs, and Presidents\n",
    "\n",
    "19/12/17\n",
    "\n",
    "Me había preguntado: ¿Por qué la felicidad promedio del twit es el promedio pesado (por frecuencia de palabras) de la felicidad promedio de cada palabra? ¿No es mejor una simple sumatoria?\n",
    "\n",
    "$h_{avg} = \\sum_i^N{h(w_i) p_i}$\n",
    "\n",
    "En esta publicación la metodología está bien explicada; debiera haber sido la primera a leer. De hecho usan el conjunto de palabras anotadas ANEW, todavía los autores no habían desarrollado el otro (???).\n",
    "\n",
    "Si una palabra aparece tres veces en un texto entonces $p_i = \\frac{f_i}{\\sum{f_i}} = \\frac{3}{\\textrm{cantidad total de palabras}}$.\n",
    "\n",
    "20/12/17\n",
    "\n",
    "### The emotional arcs of stories are dominated by six basic shapes\n",
    "\n",
    "Usan una ventana de 10.000 palabras que se corre $N_w$ palabras en cada medición (se adapta al largo del texto). De esta manera hacen que las series de todos los textos tengan la misma cantidad de mediciones.\n",
    "\n",
    "26/12/17\n",
    "\n",
    "Usan SVD para hacer una especie de clustering con series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
